{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras import backend\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = np.load('./planet_data.npz')\n",
    "    X, y = data['arr_0'], data['arr_1']\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    print(trainX.shape, testX.shape, trainY.shape, testY.shape)\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    \n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    \n",
    "    p = tp/(tp + fp + backend.epsilon())\n",
    "    r = tp/(tp + fn + backend.epsilon())\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1+bb) * (p*r) / (bb*p + r + backend.epsilon()))\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrainX, testX, trainY, testY = load_dataset()\\n\\n# make all one predictions\\ntrain_yhat = np.asarray([np.ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\\ntest_yhat = np.asarray([np.ones(testY.shape[1]) for _ in range(testY.shape[0])])\\n\\n# evaluate predictions with sklearn\\ntrain_score = fbeta_score(trainY, train_yhat, 2, average='samples')\\ntest_score = fbeta_score(testY, test_yhat, 2, average='samples')\\nprint('All Ones (sklearn): train=%.3f, test=%.3f' % (train_score, test_score))\\n\\n# evaluate predictions with keras\\ntrain_score = fbeta(backend.variable(trainY), backend.variable(train_yhat))\\ntest_score = fbeta(backend.variable(testY), backend.variable(test_yhat))\\nprint('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "trainX, testX, trainY, testY = load_dataset()\n",
    "\n",
    "# make all one predictions\n",
    "train_yhat = np.asarray([np.ones(trainY.shape[1]) for _ in range(trainY.shape[0])])\n",
    "test_yhat = np.asarray([np.ones(testY.shape[1]) for _ in range(testY.shape[0])])\n",
    "\n",
    "# evaluate predictions with sklearn\n",
    "train_score = fbeta_score(trainY, train_yhat, 2, average='samples')\n",
    "test_score = fbeta_score(testY, test_yhat, 2, average='samples')\n",
    "print('All Ones (sklearn): train=%.3f, test=%.3f' % (train_score, test_score))\n",
    "\n",
    "# evaluate predictions with keras\n",
    "train_score = fbeta(backend.variable(trainY), backend.variable(train_yhat))\n",
    "test_score = fbeta(backend.variable(testY), backend.variable(test_yhat))\n",
    "print('All Ones (keras): train=%.3f, test=%.3f' % (train_score, test_score))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(in_shape=(128, 128, 3), out_shape=17):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=in_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(out_shape, activation='sigmoid'))\n",
    "    # compile model\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fbeta])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    plt.subplot(212)\n",
    "    plt.title('Fbeta')\n",
    "    plt.plot(history.history['fbeta'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    print(\"Loading dataset...\")\n",
    "    trainX, testX, trainY, testY = load_dataset()\n",
    "    # create data generator\n",
    "    print(\"Creating data generator...\")\n",
    "    train_datagen = ImageDataGenerator(rescale=1.0/255.0, horizontal_flip=True, vertical_flip=True, rotation_range=90)\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    print(\"Preparing iterators... \")\n",
    "    train_it = train_datagen.flow(trainX, trainY, batch_size=128)\n",
    "    test_it = test_datagen.flow(testX, testY, batch_size=128)\n",
    "    # define model\n",
    "    print(\"Building model... \")\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    print(\"Training...\")\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=30, verbose=1)\n",
    "    # evaluate model\n",
    "    print(\"Evaluating...\")\n",
    "    loss, fbeta = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> loss=%.3f, fbeta=%.3f' % (loss, fbeta))\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
